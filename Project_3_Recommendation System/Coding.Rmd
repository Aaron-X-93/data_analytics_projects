---
title: "Recommendation System for Instacart"
author: "Aaron"
date: "9/16/2020"
output: pdf_document
---

### Load the libraries
```{r include=FALSE}
library(data.table)
library(ggplot2)
library(knitr)
library(stringr)
library(DT)
library(gridExtra)
library(tidyverse)
library(dplyr)
library(tidyfst)
library(treemap)
library(recommenderlab)
```

### Load the data
```{r data, include=FALSE, echo=FALSE}
orders <- fread("C:/Users/axiao/Downloads/data/instacart-market-basket-analysis/orders.csv")
products <- fread('C:/Users/axiao/Downloads/data/instacart-market-basket-analysis/products.csv')
order_products <- fread('C:/Users/axiao/Downloads/data/instacart-market-basket-analysis/order_products__train.csv')
order_products_prior <- fread('C:/Users/axiao/Downloads/data/instacart-market-basket-analysis/order_products__prior.csv')
aisles <- fread('C:/Users/axiao/Downloads/data/instacart-market-basket-analysis/aisles.csv')
departments <- fread('C:/Users/axiao/Downloads/data/instacart-market-basket-analysis/departments.csv')
```

### Peek at the dataset 1
```{r}
kable(head(orders,10))
kable(head(products,10))
kable(head(order_products,10))
kable(head(order_products_prior,10))
kable(head(aisles,10))
kable(head(departments,10))
```

### Recode variables
```{r}
orders <- orders %>% mutate(order_hour_of_day = as.numeric(order_hour_of_day), 
                            eval_set = as.factor(eval_set))
products <- products %>% mutate(product_name = as.factor(product_name))
aisles <- aisles %>% mutate(aisle = as.factor(aisle))
departments <- departments %>% mutate(department = as.factor(department))
```

## The order behaivor

### Hour of Day
```{r}
orders %>% 
  ggplot(aes(x=order_hour_of_day)) + 
  geom_histogram(stat="count",fill=rainbow(24))
```

### Day of Week
```{r}
orders %>% 
  ggplot(aes(x=order_dow)) + 
  geom_histogram(stat="count",fill=rainbow(7))
```

### When do they order again
```{r}
orders %>% 
  ggplot(aes(x=days_since_prior_order)) + 
  geom_histogram(stat="count",fill="blue")
```

### How many prior orders are there?
```{r}
prior_order = orders %>% 
  filter(eval_set=="prior") %>% 
  count(order_number)
ggplot(data = prior_order, aes(order_number,n)) +
  geom_line(color="blue", size=1) +
  geom_point(color="blue", size=2)
```

### The distributions of how many items are in the orders
```{r}
train_1 <- order_products %>% 
  group_by(order_id) %>% 
  summarize(n_items_train = last(add_to_cart_order))

ggplot(data=train_1, aes(x=n_items_train),col="red",alpha = 0.3) +
  geom_histogram(stat="count",fill="red") +
  geom_rug() +
  coord_cartesian(xlim=c(0,80))
```

### How often do people order the same items again
```{r}
re_order <- order_products %>% 
  group_by(reordered) %>% 
  summarize(count = n()) %>% 
  mutate(reordered = as.factor(reordered)) %>%
  mutate(proportion = count/sum(count))
head(re_order)
```

```{r}
ggplot(re_order, aes(x=reordered,y=count,fill=reordered))+
  geom_bar(stat="identity")
```

### Most Popular Products Sold
```{r}
tmp1 <- order_products %>%
  left_join(products) %>%
  group_by(product_name) %>%
  summarize(count=n()) %>%
  top_n(n=20, wt=count) %>%  
  mutate(percentage=count/sum(count))
p1 = ggplot (tmp1, aes(x=reorder(product_name,count), y=percentage)) +  
  geom_col() + 
  ggtitle('Products Top 20') + 
  ylab('Percentage of Orders') +
  theme (axis.text.x=element_text(angle=90, hjust=1, vjust=0.5),
         axis.title.x = element_blank()) 
p2 = ggplot (data = tmp1, aes( x= '', y=percentage )) + 
  ggtitle('Products Top 20') + 
  ylab('percentage.of.orders') + 
  geom_boxplot() + 
  xlab('Products')
grid.arrange(p1, p2, ncol = 2)
```

### Most Popular Department Sold
```{r}
tmp2 <- order_products %>%
  left_join(products) %>%
  left_join(departments) %>%
  group_by(department) %>%
  summarize(count=n()) %>%
  mutate(percentage=count/sum(count))
p1 = ggplot (tmp2, aes(x=reorder(department,count), y=percentage)) +  
  geom_col() + 
  ggtitle('Departments') + 
  ylab('Percentage of Orders') +
  theme (axis.text.x=element_text(angle=90, hjust=1, vjust=0.5),
         axis.title.x = element_blank()) 
p2 = ggplot (data = tmp2, aes( x= '', y=percentage )) + 
  ggtitle('Departments') + 
  ylab('percentage.of.orders') + 
  geom_boxplot() + 
  xlab('Departments')
grid.arrange(p1, p2, ncol = 2)
```

### Most Popular Aisles Sold
```{r}
tmp3 <- order_products %>%
  left_join(products) %>%
  left_join(aisles) %>%
  group_by(aisle) %>%
  summarize(count=n()) %>%
  top_n(n=20, wt=count) %>%  
  mutate(percentage=count/sum(count))
p5 = ggplot (tmp3, aes(x=reorder(aisle,count), y=percentage)) +  
  geom_col() + 
  ggtitle('Aisles Top 20') + 
  ylab('Percentage of Orders') +
  theme (axis.text.x=element_text(angle=90, hjust=1, vjust=0.5),
         axis.title.x = element_blank()) 
p6 = ggplot (data = tmp3, aes( x= '', y=percentage )) + 
  ggtitle('Aisles Top 20') + 
  ylab('percentage.of.orders') + 
  geom_boxplot() + 
  xlab('Products')
grid.arrange(p5, p6, ncol = 2)
```

### Top ten products ordered daily contributes between 7% to 8%.
```{r}
order_products_prior %>% 
  left_join(orders) %>% left_join(products) %>%
  group_by(order_dow, product_name) %>%
  summarize(n=n()) %>%
  mutate(percentage=n/sum(n)) %>%
  top_n(10, wt=n) %>%
  ggplot (aes(x=as.factor(order_dow), y=percentage, fill=product_name)) +
  geom_col() + ylab('Proprtion of Orders') + ggtitle('Daily Top 10 Products Ordered') +
  theme(legend.position="bottom",legend.direction="horizontal")
```

### 
```{r}
order_products_prior %>% 
  left_join(orders) %>% left_join(products) %>%
  group_by(order_hour_of_day, product_name) %>%
  summarize(n=n()) %>%
  mutate(percentage=n/sum(n)) %>%
  top_n(10, wt=n) %>%
  ggplot(aes(x=as.factor(order_hour_of_day), y=percentage, fill=product_name)) + 
  geom_col() + ylab('Proprtion of Orders In An Hour') + 
  ggtitle('Hourly Top 10 Products Ordered') +
  theme(legend.position="bottom",legend.direction="horizontal")
```

## Visualizing the Product Portfolio

### use treemap package to visualize the structure of instacarts product portfolio, 
```{r}
tmp4 <- products %>% 
  group_by(department_id, aisle_id) %>% 
  summarize(n=n()) %>% 
  left_join(departments, by="department_id") %>% 
  left_join(aisles, by="aisle_id")
```

### 
```{r}
tmp5 <-order_products %>% 
  group_by(product_id) %>% 
  summarize(count=n()) %>% 
  left_join(products, by="product_id") %>% 
  ungroup() %>% 
  group_by(department_id, aisle_id) %>% 
  summarize(sumcount = sum(count)) %>% 
  left_join(tmp4, by = c("department_id", "aisle_id")) %>% 
  mutate(onesize = 1)
```

### Visualize in aisles organized within departments?
```{r}
treemap(tmp5,index=c("department","aisle"), vSize="onesize",vColor="department", 
        palette="Set3", title="", sortID="-sumcount", border.col="#FFFFFF")
```

### How many unique products are offered in each department/aisle?
```{r}
# The size of the boxes shows the number of products in each category.
treemap(tmp5,index=c("department","aisle"),vSize="n",title="",palette="Set3",border.col="#FFFFFF")
```

### How often are products from the department/aisle sold?
```{r}
# The size of the boxes shows the number of sales.
treemap(tmp5,index=c("department","aisle"),vSize="sumcount",title="",palette="Set3",border.col="#FFFFFF")
```


## Predictive Analysis

### only select orders contains 5 to 10 items
```{r}
order_pro4 <- order_products %>% 
  group_by(order_id) %>%
  mutate(n_items = last(add_to_cart_order)) 
order_pro4 <- order_pro4 %>% 
  filter(n_items >= 5 & n_items <=10) # select part of the total data
```

### Create a training label, which is 1 or 0, to indicate the actual basket content.
```{r}
data_train = orders %>% 
  filter(eval_set=='train') %>% 
  inner_join(order_pro4) %>%
  left_join(products) %>% 
  mutate(actual = as.integer(1)) %>%   #this is training label
  select(user_id, order_id, product_id, product_name, actual)
```

### Since the data is too large, extend the memory limit to 80G
```{r}
# need enough memory to run the matrix
gc()
memory.size()
memory.limit(80000)
```

### create the rating matrix
```{r}
ratings_matrix <- data_train %>%
# Select only needed variables
  select(user_id, product_id, actual) %>%
# Spread into user-item format
  spread(product_id, actual, fill = 0) %>% 
  select(-user_id) %>%
# Convert to matrix
  as.matrix() %>%
# Convert to recommenderlab class 'binaryRatingsMatrix'
  as("binaryRatingMatrix")
ratings_matrix
```

### Evaluation Scheme and Model Validation
```{r}
scheme <- ratings_matrix %>% 
  evaluationScheme(method = "split",
                   k      = 2, 
                   train  = 0.8,  
                   given  = -1)
scheme
```

### Set up List of Algorithms
```{r}
algorithms <- list(
  "association rules" = list(name  = "AR",
                        param = list(supp = 0.01, conf = 0.01)),
  "random items"      = list(name  = "RANDOM",  param = NULL),
  "popular items"     = list(name  = "POPULAR", param = NULL),
  # "item-based CF"     = list(name  = "IBCF", param = list(k = 2)),
  # this model takes twice time than "UBCF", not able to run it
  "user-based CF"     = list(name  = "UBCF", 
                        param = list(method = "Cosine", nn = 20))
                   )
```

### Estimate the Models
```{r}
results <- recommenderlab::evaluate(scheme, 
                                    algorithms,
                                    type  = "topNList", 
                                    n     = c(3, 5, 10, 15)
                                    )
```

## Visualise the Results

### arrange the confusion matrix output for one model in a convenient format
```{r}
# Pull into a list all confusion matrix information for one model 
tmp <- results$`user-based CF` %>%
  getConfusionMatrix()  %>%  
  as.list() 
# Calculate average value of 5 cross-validation rounds 
  as.data.frame( Reduce("+",tmp) / length(tmp)) %>% 
# Add a column to mark the number of recommendations calculated
  mutate(n = c(3, 5, 10, 15)) %>%
# Select only columns needed and sorting out order 
  select('n', 'precision', 'recall', 'TPR', 'FPR')
```

```{r}
# put the previous steps into a formula
avg_conf_matr <- function(results) {
  tmp <- results %>%
    getConfusionMatrix()  %>%  
    as.list() 
    as.data.frame(Reduce("+",tmp) / length(tmp)) %>% 
    mutate(n = c(3, 5, 10, 15)) %>%
    select('n', 'precision', 'recall', 'TPR', 'FPR') 
}
```

### use the map() function from the purrr package to get all results in a tidy format, ready for charting.
```{r}
# Using map() to iterate function across all models
results_tbl <- results %>%
  map(avg_conf_matr) %>% 
# Turning into an unnested tibble
  enframe() %>%
# Unnesting to have all variables on same level
  unnest(cols = c(value))
results_tbl
```

## ROC curve

### Classification models performance can be compared using the ROC curve
```{r}
results_tbl %>%
  ggplot(aes(FPR, TPR, 
             colour = fct_reorder2(as.factor(name), 
                      FPR, TPR))) +
  geom_line() +
  geom_label(aes(label = n))  +
  labs(title = "ROC curves", colour = "Model") +
  theme_grey(base_size = 14)
```

```{r}
results_tbl %>%
  ggplot(aes(recall, precision, 
             colour = fct_reorder2(as.factor(name),  
                      precision, recall))) +
  geom_line() +
  geom_label(aes(label = n))  +
  labs(title = "Precision-Recall curves", colour = "Model") +
  theme_grey(base_size = 14)
```

## Prediction for a new user

###  create a string containing 5 products selected at random
```{r}
set.seed(64)

sample_order <- data_train %>% 
  left_join(products) %>% 
  select(product_id,product_name) %>% 
  sample_n(5) # ramdom pick n items
sample_order
```

```{r}
customer_order <- c(39821, 31562, 6844, 30960, 13914)
```

### convert the order in a format that recommenderlab accept

```{r}
gc() # clean the memory
```

```{r}
new_order_rat_matrx <- data_train %>%
  select(product_id) %>%
  group_by(product_id) %>% 
  unique() %>%
# Add a 'ref' column with 1 or 0 depends on whether it is in co
  mutate(ref = as.numeric(product_id %in% customer_order)) %>%
  spread(product_id, ref) %>%
  as.matrix() %>%
  as("binaryRatingMatrix")
```

### create a Recommender by using getData to retrieve training data and set method = “UBCF” to select the best performing model.
```{r}
recomm <- Recommender(getData(scheme, 'train'), 
                       method = "UBCF",  
                       param = list(k = 5))
recomm
# if use "popular items", the result won't change
```

### pass the Recommender and the made-up order to the predict function to create a top 5 recommendation list for the new customer.
```{r}
# need to ensure enough memory before running
pred <- predict(recomm, 
                newdata = new_order_rat_matrx, 
                n       = 5)
```

### the suggested items can be inspected as a list
```{r}
as(pred, 'list')
```

### convert to product_name to have a better idea for the items
```{r}
result_name <- products %>% 
  filter(product_id == "1215" | product_id == "1940" | product_id == "4037" | product_id == "4658" | product_id == "4913")
head(result_name)
```
```{r}
data_train %>%
  as.data.frame() %>%
  write.csv("C:\\Users\\axiao\\Downloads\\data\\final_dataset.csv", row.names = FALSE)
```
